# RAG Integration Complete ‚úÖ

The RAG (Retrieval-Augmented Generation) system is now fully integrated into your Research Agent!

## What's New

### 1. Knowledge Base Toggle

Users can now enable/disable knowledge base search directly in the Research Agent UI.

### 2. Research Depth Control

Three levels of research depth:

- **Quick** (3 docs, ~30s) - Fast summaries
- **Standard** (5 docs, ~1min) - Balanced research
- **Comprehensive** (10 docs, ~2min) - Deep analysis

### 3. Enhanced Source Display

Sources now show:

- **Type badge**: "Your KB" for knowledge base docs, "Web" for web sources
- **Relevance score**: High/Medium/Low for knowledge base documents
- **Document titles**: Clear identification of source materials

### 4. Document Count Badge

When knowledge base is used, a badge shows how many documents were retrieved.

## How It Works

### User Flow

1. **Upload Documents** (Knowledge Base page)

   - Upload PDFs, TXT, MD, JSON, HTML files
   - Documents are automatically processed and indexed
   - Status changes: pending ‚Üí processing ‚Üí indexed

2. **Enable Knowledge Base** (Research Agent page)

   - Toggle "Use Knowledge Base" switch
   - Select research depth
   - Enter research question

3. **Get RAG-Enhanced Results**
   - AI retrieves relevant documents from knowledge base
   - Combines KB context with web search
   - Generates comprehensive report with citations
   - Shows which documents were used

### Backend Architecture

```
User Query
    ‚Üì
Knowledge Retriever Agent (AgentCore Strand)
    ‚îú‚îÄ Generate query embedding (Bedrock Titan)
    ‚îú‚îÄ Search documents in DynamoDB
    ‚îú‚îÄ Calculate similarity scores
    ‚îî‚îÄ Return top K relevant chunks
    ‚Üì
Context Sharing (AgentCore)
    ‚Üì
Research Agent (AgentCore Strand)
    ‚îú‚îÄ Receive shared document context
    ‚îú‚îÄ Generate research with Claude 3.5 Sonnet
    ‚îî‚îÄ Include citations from both KB and web
    ‚Üì
Response with Sources
```

## Features Implemented

### ‚úÖ Backend (Complete)

- [x] Knowledge Retriever Agent strand
- [x] AgentCore integration with context sharing
- [x] Bedrock Titan Embeddings v2 for semantic search
- [x] Document processor with text extraction
- [x] Cosine similarity for relevance scoring
- [x] Server actions for RAG research
- [x] Citation tracking for KB documents

### ‚úÖ Frontend (Complete)

- [x] Knowledge Base toggle in UI
- [x] Research depth selector
- [x] Document count badge
- [x] Enhanced source display with type badges
- [x] Relevance indicators
- [x] Loading states for RAG research
- [x] Error handling and user feedback

## Usage Examples

### Basic Research with Knowledge Base

```typescript
// User enables KB toggle and enters query
// System automatically:
1. Retrieves 5 relevant documents from KB
2. Generates embeddings for query
3. Calculates similarity scores
4. Shares context with research agent
5. Generates comprehensive report
6. Shows KB documents used in sources
```

### Quick Research (No KB)

```typescript
// User disables KB toggle
// System uses only web search and general knowledge
// Faster but without personalized context
```

### Comprehensive Research

```typescript
// User selects "Comprehensive" depth
// System retrieves 10 documents
// Takes ~2 minutes for thorough analysis
// Best for complex topics
```

## Testing the Integration

### 1. Upload Test Documents

Navigate to `/intelligence/knowledge` and upload:

- Market reports (PDF/TXT)
- Neighborhood guides (MD)
- Property data (JSON)
- Research notes (TXT)

### 2. Wait for Processing

Documents show status:

- ‚è≥ **Pending** - Just uploaded
- üîÑ **Processing** - Extracting text
- ‚úÖ **Indexed** - Ready for search
- ‚ùå **Failed** - Check error message

### 3. Test Research Query

Go to `/intelligence/agent` and try:

- "What neighborhoods are mentioned in my documents?"
- "Summarize the market trends from my reports"
- "What properties are in my knowledge base?"

### 4. Verify Results

Check that:

- Document count badge appears
- Sources show "Your KB" badge
- Relevance scores are displayed
- Report includes KB context

## Current Limitations

### Document Processing

- ‚úÖ TXT, MD, JSON, HTML - Fully supported
- üöß PDF - Requires Lambda with pdf-parse
- üöß DOCX - Requires Lambda with mammoth

### Performance

- ‚ö†Ô∏è Embeddings generated on-demand (slow)
- ‚ö†Ô∏è No vector database (in-memory search)
- ‚ö†Ô∏è No caching (every query regenerates embeddings)

### Optimization Needed

1. Pre-compute embeddings during upload
2. Store embeddings in Pinecone/OpenSearch
3. Implement caching for frequent queries
4. Add Lambda for PDF/DOCX processing

## Next Steps

### Phase 1: Production Optimization

- [ ] Lambda function for document processing
- [ ] PDF and DOCX text extraction
- [ ] Pre-computed embeddings storage
- [ ] Vector database integration (Pinecone)

### Phase 2: Enhanced Features

- [ ] Hybrid search (semantic + keyword)
- [ ] Query expansion and rewriting
- [ ] Multi-hop reasoning
- [ ] Citation verification

### Phase 3: Team Features

- [ ] Team knowledge bases
- [ ] Document sharing and permissions
- [ ] Collaborative research
- [ ] Usage analytics

## Configuration

### Environment Variables

```bash
# AWS Configuration
AWS_REGION=us-west-2
AWS_ACCESS_KEY_ID=your_key
AWS_SECRET_ACCESS_KEY=your_secret

# Knowledge Base
KNOWLEDGE_BASE_BUCKET=bayon-knowledge-base
KNOWLEDGE_BASE_TABLE=KnowledgeBaseDocuments
```

### Retrieval Settings

Default settings in `knowledge-retriever.ts`:

- **Chunk size**: 500 characters
- **Chunk overlap**: 50 characters
- **Embedding model**: amazon.titan-embed-text-v2:0
- **Embedding dimensions**: 1024
- **Min similarity score**: 0.5

### Research Settings

Configurable in UI:

- **Quick**: 3 docs, ~30 seconds
- **Standard**: 5 docs, ~1 minute
- **Comprehensive**: 10 docs, ~2 minutes

## Troubleshooting

### Documents Not Retrieved

**Problem**: Research doesn't use KB documents

**Solutions**:

1. Check document status is "indexed"
2. Verify extractedText is populated in DynamoDB
3. Lower minScore threshold (default 0.5)
4. Increase topK value
5. Try more specific queries

### Slow Performance

**Problem**: Research takes too long

**Solutions**:

1. Use "Quick" depth for faster results
2. Reduce number of documents in KB
3. Implement vector database (future)
4. Pre-compute embeddings (future)

### Processing Failures

**Problem**: Documents stuck in "processing"

**Solutions**:

1. Check file type is supported (TXT, MD, JSON, HTML)
2. Verify S3 upload succeeded
3. Check DynamoDB write permissions
4. Review error message in document.errorMessage
5. For PDF/DOCX, implement Lambda processor

## Support & Documentation

- **Full Implementation Guide**: `src/aws/bedrock/RAG_IMPLEMENTATION.md`
- **AgentCore Documentation**: `src/aws/bedrock/agent-core.ts`
- **Knowledge Actions**: `src/features/intelligence/actions/knowledge-actions.ts`
- **Research Actions**: `src/app/research-rag-actions.ts`

## Success Metrics

Track these to measure RAG effectiveness:

- Document retrieval accuracy
- User satisfaction with results
- Knowledge base usage rate
- Average documents per query
- Research completion time

## Conclusion

Your RAG system is now live! Users can upload documents to their knowledge base and get personalized, context-aware research results. The system uses your existing AgentCore architecture for intelligent multi-agent coordination.

Start by uploading some test documents and trying research queries that reference them. The system will automatically retrieve relevant context and include it in the research report.
